# StreamLit - Traitement de MÃ©dias avec AWS

## ğŸ“¸ Description

Ce projet utilise des services AWS pour traiter des fichiers multimÃ©dias (images et vidÃ©os). Il permet de modÃ©rer le contenu, dÃ©tecter des objets, identifier des Ã©motions sur les visages et extraire des sous-titres et des hashtags pertinents Ã  partir des mÃ©dias. L'objectif est de proposer une solution automatisÃ©e pour l'analyse d'images et vidÃ©os, en tirant parti des puissants outils d'Amazon Web Services (AWS) comme Rekognition, Transcribe, et Comprehend.

## FonctionnalitÃ©s

- **ğŸš« ModÃ©ration du contenu** : DÃ©tection de contenus choquants ou inappropriÃ©s dans les images et vidÃ©os.
- **ğŸ˜Š Analyse des Ã©motions** : DÃ©tection des Ã©motions dominantes des visages dans les images.
- **ğŸ” DÃ©tection des objets et des cÃ©lÃ©britÃ©s** : Identification des objets et cÃ©lÃ©britÃ©s prÃ©sents sur les images.
- **ğŸ“ Extraction de texte dans les vidÃ©os** : Utilisation d'AWS Transcribe pour convertir la voix en texte, puis extraction des mots-clÃ©s avec AWS Comprehend.
- **ğŸ”– GÃ©nÃ©ration automatique de hashtags** : CrÃ©ation de hashtags en fonction des objets, Ã©motions et cÃ©lÃ©britÃ©s dÃ©tectÃ©s.

## ğŸ› ï¸ PrÃ©requis

- Python 3.7+ installÃ©
- AWS CLI configurÃ© avec vos clÃ©s d'accÃ¨s
- Installation des packages nÃ©cessaires :
  - `boto3`
  - `dotenv`
  - `opencv-python`

## ğŸ’» Installation

1. Clonez le repository sur votre machine locale :
   ```bash
   git clone https://github.com/votre-utilisateur/project-name.git

CrÃ©ez un environnement virtuel et activez-le :
  ```bash
  python3 -m venv venv
  source venv/bin/activate  # Sur Windows, utilisez `venv\Scripts\activate`
  ```

Installez les dÃ©pendances :
  ```bash
  pip install -r requirements.txt
  ```

CrÃ©ez un fichier .env Ã  la racine du projet et ajoutez vos clÃ©s d'accÃ¨s AWS :
  ```bash
  ACCESS_KEY=votre_access_key_id
  SECRET_KEY=votre_secret_access_key
  ```

Assurez-vous que vos vidÃ©os et images de test sont dans le dossier ./assets/.

# ğŸ“ˆ Usage
**Tester le traitement sur une image :**
- Modifiez la variable TEST_IMAGE_FILE avec le chemin de votre image de test.
- Appelez la fonction process_media en fournissant l'image et les clients AWS appropriÃ©s.

**Tester le traitement sur une vidÃ©o :**
- Modifiez la variable TEST_VIDEO_FILE avec le chemin de votre vidÃ©o de test.
- Appelez la fonction process_media pour traiter la vidÃ©o et obtenir les sous-titres et hashtags.

  ```bash
  image_result = process_media(TEST_IMAGE_FILE, rekognition, transcribe, comprehend, BUCKET_NAME)
  video_result = process_media(TEST_VIDEO_FILE, rekognition, transcribe, comprehend, BUCKET_NAME)
  ```

# ğŸ“‚ Structure du Dossier
  ```bash
  â”œâ”€â”€ assets/
  â”‚   â”œâ”€â”€ tuto_jeux-video.mp4
  â”‚   â””â”€â”€ selfie_with_johnny-depp.png
  â”œâ”€â”€ .env
  â”œâ”€â”€ README.md
  â””â”€â”€ process_media.py
  ```

# ğŸ“Š Exemple de RÃ©sultats
**Pour une image :**
La fonction retourne un dictionnaire de hashtags :

  ```bash
  {
    "hashtags": ["#JohnnyDepp", "#Selfie", "#Fan"]
  }
  ```

**Pour une vidÃ©o :**
La fonction retourne des sous-titres et des hashtags extraits :

  ```bash
  {
    "subtitles": "Bienvenue dans ce tutoriel de jeu vidÃ©o, aujourd'hui nous allons...",
    "hashtags": ["#JeuxVidÃ©o", "#Tutoriel", "#Gaming"]
  }
  ```

# ğŸ” Aide
Si vous avez besoin de plus d'informations, consultez la documentation AWS Rekognition, AWS Transcribe et AWS Comprehend.